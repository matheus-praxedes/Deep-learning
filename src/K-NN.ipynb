{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Instance, DataSet\n",
    "from miscellaneous import initialize_data, plot_graph, plot_points\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsRegressor as knn\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados ............................... OK\n",
      "Ajustando nomes[1] ............................. OK\n",
      "Ajustando nomes[2] ............................. OK\n",
      "Removendo instâncias desnecessárias ............ OK\n",
      "Reduzindo dimensionalidade ..................... OK\n",
      "Removendo atributos desnecessários ............. OK\n",
      "Juntando tabelas .................. OK\n",
      "One-hot encoding para role e position .......... OK        \n",
      "Substituindo IDs por nomes dos champions ....... OK       \n",
      "Juntando tabelas ............................... OK\n",
      "Normalizando duração ....................... OK\n",
      "Removendo o nome dos champios .................. OK      \n",
      "Reconstruindo linhas apropriadamente ........... OK\n",
      "Removendo dados duplicados ........... OK\n",
      "Normalizando duração ....................... OK\n",
      "Calculando dificuldade ....................... OK\n",
      "Tempo total ................................. 04:24\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Carregando dados\n",
    "print('Carregando dados ...', end = '')\n",
    "champ_stats = pd.read_csv('../dataset/champ_stats.csv')\n",
    "champs = pd.read_csv('../dataset/champs.csv')\n",
    "mtime = pd.read_csv('../dataset/matches_MODIFIED.csv')\n",
    "participants = pd.read_csv('../dataset/participants.csv')\n",
    "stats1 = pd.read_csv('../dataset/stats1_MODIFIED.csv')\n",
    "stats2 = pd.read_csv('../dataset/stats2_MODIFIED.csv')\n",
    "stats = pd.concat([stats1, stats2])\n",
    "print( 28*'.'+' OK')\n",
    "\n",
    "# Ajustando nomes\n",
    "print('Ajustando nomes[1] ...', end = '')\n",
    "champ_stats_labels = [i.lower() for i in champ_stats.columns.values]\n",
    "rename_dict_champ_stats = { i: j for i,j in zip(champ_stats.columns.values, champ_stats_labels) }\n",
    "champ_stats.rename(columns = rename_dict_champ_stats, inplace = True)\n",
    "print( 26*'.'+' OK')\n",
    "\n",
    "# Ajustando nomes\n",
    "print('Ajustando nomes[2] ...', end = '')\n",
    "champs_labels = [i.lower() for i in champs.columns.values]\n",
    "rename_dict_champs = { i: j for i,j in zip(champs.columns.values, champs_labels) }\n",
    "champs.rename(columns = rename_dict_champs, inplace = True)\n",
    "print( 26*'.'+' OK')\n",
    "\n",
    "# Removendo instâncias desnecessárias\n",
    "print('Removendo instâncias desnecessárias ...', end = '')\n",
    "champ_stats['name'] = champ_stats['name'].str.replace('\\'', '')\n",
    "champ_stats['name'] = champ_stats['name'].str.replace('\\. ', '')\n",
    "champ_stats = champ_stats[champ_stats['name'].isin(champs['name'])].reset_index(drop = True)\n",
    "champs = champs.sort_values('name').reset_index(drop = True)\n",
    "print( 9*'.'+' OK')\n",
    "\n",
    "# Reduzindo dimensionalidade\n",
    "print('Reduzindo dimensionalidade ...', end = '')\n",
    "params = ['hp', 'hp5', 'mp', 'mp5', 'ad', 'ar', 'mr']\n",
    "for param in params:\n",
    "    champ_stats[param] = champ_stats[param] + 10*champ_stats[param+'+']\n",
    "    champ_stats.drop(columns = [param+'+'], inplace = True)\n",
    "    \n",
    "champ_stats['as'] = champ_stats['as'] * ((1 + champ_stats['as+'])**10)\n",
    "champ_stats.drop(columns = ['as+'], inplace = True)\n",
    "print( 18*'.'+' OK')\n",
    "\n",
    "# Removendo atributos desnecessários\n",
    "print('Removendo atributos desnecessários ...', end = '')\n",
    "#participants.drop(columns = ['player', 'ss1', 'ss2', 'id', 'matchid'], inplace = True)\n",
    "participants.drop(columns = ['player', 'ss1', 'ss2'], inplace = True)\n",
    "stats.drop(columns = ['trinket', 'assists', 'firstblood'], inplace = True)\n",
    "print( 10*'.'+' OK')\n",
    "\n",
    "# Juntando tabelas\n",
    "print('Juntando tabelas ...', end = '')\n",
    "participants.set_index('id', inplace = True)\n",
    "stats.set_index('id', inplace = True)\n",
    "dataset = pd.DataFrame.copy(participants)\n",
    "dataset = dataset.join(pd.DataFrame.copy(stats))\n",
    "print( 15*'.'+' OK')\n",
    "\n",
    "# One-hot encoding para role e position\n",
    "print('One-hot encoding para role e position ...', end = '')\n",
    "dataset = pd.concat([dataset, pd.get_dummies( dataset['role'], prefix = 'role')],axis=1)\n",
    "dataset = pd.concat([dataset, pd.get_dummies( dataset['position'], prefix = 'pos')],axis=1)\n",
    "dataset.drop(['role', 'position'], axis = 1, inplace = True)\n",
    "if 'role_DUO' not in dataset.columns.values:\n",
    "    dataset['role_DUO'] = 0\n",
    "print( 7*'.'+' OK        ')\n",
    "\n",
    "# Substituindo IDs por nomes dos champions\n",
    "print('Substituindo IDs por nomes dos champions ...', end = '')\n",
    "s = champs.set_index('id')['name']\n",
    "dataset['championid'] = dataset['championid'].replace(s)\n",
    "print( 4*'.'+' OK       ')\n",
    "        \n",
    "# Juntando tabelas\n",
    "print('Juntando tabelas ...', end = '')\n",
    "params = ['hp', 'hp5', 'mp', 'mp5', 'ad', 'ar', 'as', 'mr', 'ms', 'range']\n",
    "s = champ_stats.set_index('name')\n",
    "for param in params:\n",
    "    dataset[param] = dataset['championid']\n",
    "    dataset[param] = dataset[param].replace(s[param])\n",
    "dataset = dataset.reset_index(drop = True)\n",
    "print( 28*'.'+' OK')\n",
    "\n",
    "# Normalizando parametros\n",
    "print('Normalizando duração ...', end = '')\n",
    "min_max_s = MinMaxScaler(feature_range = (0.0, 1.0))\n",
    "for col in ['hp', 'hp5', 'mp', 'mp5', 'ad', 'ar', 'mr', 'ms', 'range']:\n",
    "    dataset[col] = min_max_s.fit_transform(dataset[col].values.reshape(-1, 1))\n",
    "print( 20*'.'+' OK')\n",
    "\n",
    "# Removendo o nome dos champios\n",
    "print('Removendo o nome dos champios ...', end = '')\n",
    "dataset.drop(columns = ['championid'], inplace = True)\n",
    "print( 15*'.'+' OK      ')\n",
    "\n",
    "# Reconstruindo linhas apropriadamente\n",
    "print('Reconstruindo linhas apropriadamente ...', end = '')\n",
    "tmp = pd.DataFrame()\n",
    "columnNames = dataset.columns.values.tolist()\n",
    "p = 0\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ij = str(i)+str(j)\n",
    "        p = dataset[i*5+j::10].rename( columns = { name: name+ij for name in columnNames} )\n",
    "        if(tmp.empty):\n",
    "            tmp = pd.DataFrame.copy(p).reset_index(drop = True)\n",
    "        else:\n",
    "            tmp = tmp.join(pd.DataFrame.copy(p).reset_index(drop = True))\n",
    "dataset = tmp\n",
    "print( 8*'.'+' OK')\n",
    "\n",
    "# Removendo dados duplicados\n",
    "print('Removendo dados duplicados ...', end = '')\n",
    "dataset.dropna()\n",
    "dataset['matchid'] = dataset['matchid00']\n",
    "dataset['win0'] = dataset['win00']\n",
    "dataset['win1'] = dataset['win10']\n",
    "dataset['kills0'] = dataset['kills00'] + dataset['kills01'] + dataset['kills02'] + dataset['kills03'] + dataset['kills04']\n",
    "dataset['kills1'] = dataset['kills10'] + dataset['kills11'] + dataset['kills12'] + dataset['kills13'] + dataset['kills14']\n",
    "dataset['deaths0'] = dataset['deaths00'] + dataset['deaths01'] + dataset['deaths02'] + dataset['deaths03'] + dataset['deaths04']\n",
    "dataset['deaths1'] = dataset['deaths10'] + dataset['deaths11'] + dataset['deaths12'] + dataset['deaths13'] + dataset['deaths14']\n",
    "dataset['kd_ratio0'] = dataset['kills0']/dataset['deaths0']\n",
    "dataset['kd_ratio1'] = dataset['kills1']/dataset['deaths1']\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ij = str(i)+str(j)\n",
    "        dataset.drop(columns = ['win'+ij, 'kills'+ij, 'deaths'+ij, 'matchid'+ij], inplace = True)\n",
    "    dataset.drop(columns = ['deaths'+str(i), 'kills'+str(i)], inplace = True)\n",
    "\n",
    "dataset = dataset.join(mtime)\n",
    "dataset.drop(columns = ['id', 'matchid'], inplace = True)\n",
    "print( 8*'.'+' OK')\n",
    "\n",
    "# Normalizando duração\n",
    "print('Normalizando duração ...', end = '')\n",
    "min_max_s = MinMaxScaler(feature_range = (0.0, 1.0))\n",
    "for col in ['duration']:\n",
    "    dataset[col] = min_max_s.fit_transform(dataset[col].values.reshape(-1, 1))\n",
    "print( 20*'.'+' OK')\n",
    "\n",
    "# Calculando dificuldade\n",
    "print('Calculando dificuldade ...', end = '')\n",
    "kd0 = pd.Series.copy(dataset['kd_ratio0'])\n",
    "kd0[ kd0 > 1.0 ] = 1.0\n",
    "kd0[ kd0 < 1.0 ] = 0.0\n",
    "kd1 = 1.0 - kd0\n",
    "win0 = dataset['win0']\n",
    "win1 = dataset['win1']\n",
    "\n",
    "durationTerm = 1.0 - dataset['duration']\n",
    "killTerm = 0.5 + 0.5 * (dataset['kd_ratio0'] * kd1 + dataset['kd_ratio1'] * kd0) * (win0 * kd0 + win1 * kd1) - 0.5 * (dataset['kd_ratio0'] * kd1 + dataset['kd_ratio1'] * kd0) * (win0 * kd1 + win1 * kd0)\n",
    "    \n",
    "dataset['dificult'] = durationTerm * 0.4 + killTerm * 0.6\n",
    "dataset['dificult0'] = 0.5 + 0.5*( dataset['dificult'] * dataset['win1'] - dataset['dificult'] * dataset['win0']  )\n",
    "dataset['dificult1'] = 0.5 + 0.5*( dataset['dificult'] * dataset['win0'] - dataset['dificult'] * dataset['win1']  )\n",
    "dataset.drop(columns = ['win0', 'win1', 'dificult', 'duration'], inplace = True)\n",
    "print( 20*'.'+' OK')\n",
    "        \n",
    "elapsed_time = time.time() - start_time\n",
    "print('Tempo total ' + 33*'.' + ' ' + time.strftime(\"%M:%S\", time.gmtime(elapsed_time)))\n",
    "                                                       \n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ij = str(i)+str(j)\n",
    "        dataset.drop(columns = ['hp5'+ij, 'mr'+ij, 'role_NONE'+ij], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tudo OK\n"
     ]
    }
   ],
   "source": [
    "new_io = pd.DataFrame.copy(dataset)\n",
    "new_io = new_io.dropna()\n",
    "params = new_io.columns.values.tolist()\n",
    "\n",
    "team0win = new_io[new_io['dificult0'] < 0.25].filter(params[0:80])\n",
    "team1win = new_io[new_io['dificult1'] < 0.25].filter(params[80:160])\n",
    "\n",
    "x = team0win.filter(params[0:64], axis = 1)\n",
    "y = team0win.filter(params[64:80], axis = 1)\n",
    "\n",
    "finalDataset = DataSet() \n",
    "for inst_x, inst_y in zip(x.iterrows(), y.iterrows()):\n",
    "    index_x, data_x = inst_x\n",
    "    index_y, data_y = inst_y\n",
    "    finalDataset.add(Instance(data_x.tolist(), data_y.tolist()))\n",
    "    \n",
    "x = team1win.filter(params[80:144], axis = 1)\n",
    "y = team1win.filter(params[144:160], axis = 1)\n",
    "\n",
    "for inst_x, inst_y in zip(x.iterrows(), y.iterrows()):\n",
    "    index_x, data_x = inst_x\n",
    "    index_y, data_y = inst_y\n",
    "    finalDataset.add(Instance(data_x.tolist(), data_y.tolist()))\n",
    "\n",
    "if(new_io.isnull().values.any()):\n",
    "    print(new_io.isnull().sum().sum())\n",
    "else:\n",
    "    print('Tudo OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02968412978321977\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for inst in finalDataset.data():\n",
    "    X.append(inst.input)\n",
    "    y.append(inst.expected_output)\n",
    "\n",
    "neigh = knn(n_neighbors = 3, weights = 'distance', algorithm = 'kd_tree', n_jobs = 2)\n",
    "neigh.fit(X[0:int(finalDataset.size()*0.8)], y[0:int(finalDataset.size()*0.8)])\n",
    "\n",
    "print(mean_squared_log_error(neigh.predict(X[int(finalDataset.size()*0.8):]), y[int(finalDataset.size()*0.8):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027715326192116495\n"
     ]
    }
   ],
   "source": [
    "neigh = knn(n_neighbors = 5, weights = 'distance', algorithm = 'kd_tree', n_jobs = 2)\n",
    "neigh.fit(X[0:int(finalDataset.size()*0.8)], y[0:int(finalDataset.size()*0.8)])\n",
    "\n",
    "print(mean_squared_log_error(neigh.predict(X[int(finalDataset.size()*0.8):]), y[int(finalDataset.size()*0.8):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026879149747582327\n"
     ]
    }
   ],
   "source": [
    "neigh = knn(n_neighbors = 7, weights = 'distance', algorithm = 'kd_tree', n_jobs = 2)\n",
    "neigh.fit(X[0:int(finalDataset.size()*0.8)], y[0:int(finalDataset.size()*0.8)])\n",
    "\n",
    "print(mean_squared_log_error(neigh.predict(X[int(finalDataset.size()*0.8):]), y[int(finalDataset.size()*0.8):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026805896183037414\n"
     ]
    }
   ],
   "source": [
    "neigh = knn(n_neighbors = 7, weights = 'uniform', algorithm = 'kd_tree', n_jobs = 2)\n",
    "neigh.fit(X[0:int(finalDataset.size()*0.8)], y[0:int(finalDataset.size()*0.8)])\n",
    "\n",
    "print(mean_squared_log_error(neigh.predict(X[int(finalDataset.size()*0.8):]), y[int(finalDataset.size()*0.8):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02639638293407264\n"
     ]
    }
   ],
   "source": [
    "neigh = knn(n_neighbors = 101, weights = 'distance', algorithm = 'kd_tree', n_jobs = 2)\n",
    "neigh.fit(X[0:int(finalDataset.size()*0.8)], y[0:int(finalDataset.size()*0.8)])\n",
    "\n",
    "print(mean_squared_log_error(neigh.predict(X[int(finalDataset.size()*0.8):]), y[int(finalDataset.size()*0.8):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
