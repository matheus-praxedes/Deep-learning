{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "from data import Instance, DataSet\n",
    "from miscellaneous import initialize_data, plot_graph, plot_points\n",
    "from neural_network import NeuralNetwork\n",
    "from activation_function import ActivationFunction, step_func, sig_func, tanh_func, relu_func\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questão 01**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é a criação do conjunto de dados, que será usado para treinamento, validação e teste. Neste primeiro caso, resolvemos criar uma base de dados, gerada aleatoriamente, com 1000 instâncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_1 = initialize_data(\"data_set_1\", 1000, seed = 11403723)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos traçar um gráfico a partir dos dados gerados, para verificar se estão de acordo com o desejado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data\n",
    "aux_1 = [ inst.input for inst in data_set_1.data() ]\n",
    "plot_points([aux_1], \"Square\", \"x\", \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos, então, uma rede neural com as características desejadas, escolhendo o número de entradas (de acordo com os dados gerados), número de neurônios em cada uma das camadas e a função de ativação para cada uma delas. Neste caso, escolhemos 3 entradas e criamos uma rede com uma única camada, contendo 8 neurônios e usando a função Degrau.\n",
    "\n",
    "Depois de criada a rede, iniciamos o treinamento, fornecendo os dados gerados anteriormente, dizendo o tipo de treinamento (estocástico, neste caso), o número de épocas desejado (10), a taxa de aprendizagem (0.1), o tipo do problema (classificação) e uma lista indicando a razão desejada entre os conjuntos de treinamento, validação e teste (razão 7:2:1, neste caso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = NeuralNetwork(3, [8], [step_func], seed = 11403723)\n",
    "data_1 = net_1.fit(data_set_1, \"stochastic\", 10, learning_rate = 0.1, type = \"class\", tvt_ratio = [7, 2, 1], \n",
    "                            print_info = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treinameno, podemos então traçar um gráfico que relaciona a evolução do erro com o número de épocas de treinamento. Vejamos abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_1, \"Problem 1 - Step\", \"Epoch\", \"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questão 01 - Solução alternativa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, para a mesma questão podemos ter outras soluções. A solução abaixo utiliza uma rede com duas camadas, sendo uma de entrada e outra de saída (nenhuma camada oculta). Ela também usa uma função de ativação diferente (sigmoid) e utiliza mais épocas para treinar (50), mantendo as outras características da primeira rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1b = NeuralNetwork(3, [3, 8], 2*[sig_func], 11403723)\n",
    "data_1b = net_1b.fit(data_set_1, \"stochastic\", 50, learning_rate = 0.1, type = \"class\", tvt_ratio = [7, 2, 1], \n",
    "                              print_info = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver novamente o gráfico que relaciona evolução do erro e número de épocas do treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_1b, \"Problem 1 - Sigmoid\", \"Epoch\", \"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questão 03 - a**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta questão e nas subsequentes, repetiremos os mesmos passos da primeira questão. Começamos inicializando e visualizando os dados, que referem-se ao funcionamento de uma porta lógica **xor**, com a entrada sendo um par (cada elemento sendo 0 ou 1) e cada saída sendo um valor 0 ou 1. Após a geração, seguimos para o treinamento da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_3a = initialize_data(\"data_set_3a\", 100, seed = 11403723)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data\n",
    "aux_3a = [ inst.input for inst in data_set_3a.data() ]\n",
    "plot_points([aux_3a], \"XOR\", \"A\", \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta rede da terceira questão, decidimos usar 3 camadas (uma de entrada, uma de saída, uma oculta), cada uma utilizando a função de ativação *sigmoid*. Usamos duas entradas, já que nossos dados de entrada são pares de números (0 ou 1), e uma saída, representando a saída da nossa porta **xor**. Neste caso, usamos um treinamento estocástico e escolhemos o tipo regressão para a rede. Interessante notar que este exemplo é do tipo onde *overfitting* não é um problema, já que todas as instâncias são conhecidas e usadas no treinamento. Desta forma, usar muitas épocas não representa um problema (a não ser pelo custo computacional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic\n",
    "net_3a1 = NeuralNetwork(2, [2, 4, 1], 3*[sig_func], seed = 11403723)\n",
    "data_3a1 = net_3a1.fit(data_set_3a, \"stochastic\", 800, learning_rate = 0.2, type = \"reg\", tvt_ratio = [7, 2, 1], \n",
    "                                print_info = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotamos o resultado da rede, relacionando o Erro Médio Quadrático (MSE - *Mean Squared Error*) a cada época passada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_3a1, \"Problem 3.a - Sigmoid/Stochastic\", \"Epoch\", \"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta próxima rede, trocamos o modo de aprendizado de *estocástico* para *em lotes*. Ajustamos o número de neurônios em cada camada, bem como a quantidade de camadas (2) e a quantidade de épocas (500). Mantivemos, porém, o mesmo conjunto de dados da rede anterior, a fim de comparar o funcionamento de ambas. Depois do treinamento, é possível verificar a evolução do MSE com o passar das épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch\n",
    "net_3a2 = NeuralNetwork(2, [4, 6, 1], 4*[tanh_func], seed = 11403723)\n",
    "data_3a2 = net_3a2.fit(data_set_3a, \"batch\", 50, learning_rate = 0.001, type = \"reg\", tvt_ratio = [7, 2, 1],\n",
    "                       print_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_graph(data_3a2, \"Problem 3.a - Sigmoid/Batch\", \"Epoch\", \"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, criamos uma terceira rede para resolver a questão, desta vez com treinamento estocástico, mas fazendo uso do *momento*. Assim, usamos os mesmos parâmetros da primeira rede, porém, usando um *momento* com valor 0.25 (não usá-lo equivale ao valor 0). Logo após, podemos ver o gráfico deste treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic + Momentum\n",
    "net_3a3 = NeuralNetwork(2, [2, 4, 1], 3*[sig_func], seed = 11403723)\n",
    "data_3a3 = net_3a3.fit(data_set_3a, \"stochastic\", 500, learning_rate = 0.2, type = \"reg\", tvt_ratio = [7, 2, 1],\n",
    "                        momentum = 0.5, print_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_3a3, \"Problem 3.a - Sigmoid/Estocástico/Momentum\", \"Epoch\", \"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questão 03 - b**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta próxima questão, o objetivo é aproximar uma função real dada. Geramos os dados, que nada mais são que (1000) pares de entradas e saídas desta função (entrada e saída são formadas por um único número real) e assim como nos casos anteriores, podemos visualizar os dados gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_3b = initialize_data(\"data_set_3b\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data\n",
    "aux_3b = [[inst.input, inst.expected_output] for inst in data_set_3b.data()]\n",
    "plot_points([aux_3b], \"Sin Function\", \"x\", \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no caso anterior (3-a), criamos então 3 redes distintas. A primeira delas utiliza treinamento **estocástico**, a segunda, **por lote** e a terceira, também estocástico, mas utilizando o **termo do momento**. Cada uma foi configurada com os valores considerados mais adequados para cada parâmetro, variando o número de épocas, número de camadas e a quantidade de neurônios por camada. O conjunto de dados gerado acima foi usado nos três casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, treinamento estocástico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic\n",
    "net_3b1 = NeuralNetwork(1, [5, 3, 1], 3*[tanh_func], seed = 11403723)\n",
    "data_3b1 = net_3b1.fit(data_set_3b, \"stochastic\", 500, learning_rate = 0.1, type = \"reg\", tvt_ratio = [7, 2, 1], \n",
    "                        print_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_3b1, \"Problem 3.b - Sigmoid/Stochastic\", \"Epoch\", \"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, treinamento por lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch\n",
    "net_3b2 = NeuralNetwork(1, [6, 4, 6, 1], [tanh_func, tanh_func, tanh_func, tanh_func, tanh_func])\n",
    "data_3b2 = net_3b2.fit(data_set_3b, \"batch\", 200, learning_rate = 0.5, type = \"reg\", tvt_ratio = [7, 2, 1], \n",
    "                        print_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_3b2, \"Problem 3.b - Sigmoid/Batch\", \"Epoch\", \"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, treinamento estocástico utlizando o termo do momento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic + Momentum\n",
    "net_3b3 = NeuralNetwork(1, [5, 3, 1], 3*[tanh_func], seed = 11403723)\n",
    "data_3b3 = net_3b3.fit(data_set_3b, \"stochastic\", 500, learning_rate = 0.1, type = \"reg\", tvt_ratio = [7, 2, 1], \n",
    "                        momentum = 0.5, print_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_3b3, \"Problem 3.b - Sigmoid/Estocástico/Momentum\", \"Epoch\", \"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grafico\n",
    "aux_ex = []\n",
    "for instance in range(1, 400):\n",
    "    net_3b3.classify([instance/100])\n",
    "    aux_ex.append([instance/100, net_3b3.output[0]])\n",
    "\n",
    "plot_points([aux_3b, aux_ex], \"Sin Function\", \"x\", \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questão 04**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui temos um conjunto de pontos distribuídos no interior de uma circunferência de raio 1, entrada na origem dos eixos cartesianos. Devemos então classificar, através de nossa rede, os pontos fornecidos, dizendo a qual grupo, dentre 8 definidos, eles pertencem. O conjunto de treinamento consiste, então, de entradas formadas por 2 elementos (coordenadas x e y do ponto) e uma saída composta por 8 valores, cada um representando uma das saídas quando ativado (maior que 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_4 = initialize_data(\"data_set_4\", 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data\n",
    "aux_4 = [inst.input for inst in data_set_4.data()]\n",
    "plot_points( [aux_4], \"Circle\", \"x\", \"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver nosso problema, criamos a rede neural abaixo, que possui 4 camadas, sendo 2 ocultas, formada 22 neurônios no total e usando a função de ativação sigmoid. No treinamento, usamos 500 épocas, uma taxa de aprendizagem de 0.15 e um momentum de 0.5. O problema, como já (implicitamente) mencionado, é de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_4 = NeuralNetwork(2, [2, 6, 6, 8], [sig_func, sig_func, sig_func, sig_func])\n",
    "data_4 = net_4.fit(data_set_4, \"stochastic\", 500, learning_rate = 0.02, type = \"class\", tvt_ratio = [7, 2, 1],\n",
    "                        momentum = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos gerar e visualizar um gráfico que representa a evolução do erro com o passar das épocas do treinamento. Observe que o erro estabilizou em um valor razoavelmente alto, apesar do número de épocas relativamente alto usado em relação aos outros problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_4, \"Problem 4\", \"Epoch\", \"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Questão 05**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste último problema, precisamos prevê os próximos 3 valores de uma sequência com base nos 10 anteriores. Logo, nos nossos dados de treinamento, a entrada é um vetor com 10 elementos e a saída correspondente é um vetor de 3 elementos. Usamos 100 objetos para o treinamento. Como os dados são muito complexos, não é possível visualizá-los, como nos casos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_5 = initialize_data(\"data_set_5\", 1000, seed = 11403723)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta vez, criamos uma rede com 5 camadas (3 ocultas), usando a função de ativação sigmoid. Setamos os demais valores, treinando por 100 épocas. O resultado pode ser plotado e visto logo após a execução da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_5 = NeuralNetwork(10, [4, 3], 3*[tanh_func], seed = 11403723)\n",
    "data_5 = net_5.fit(data_set_5, \"stochastic\", 1000, learning_rate = 0.05, type = \"reg\", tvt_ratio = [7, 2, 1],\n",
    "                       momentum = 0.5, print_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_5, \"Problem 5 - Sigmoid/Stochastic\", \"Epoch\", \"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico\n",
    "data_t = [[], [], [], [], []]\n",
    "x_size = 100\n",
    "for n in range(x_size):\n",
    "    sin_n = np.sin(n)\n",
    "    data_t[0].append( n )\n",
    "    data_t[1].append( np.sin(n + sin_n*sin_n) )\n",
    "\n",
    "data_t[2] = data_t[1][0:11]\n",
    "for n in range(10, x_size-1):   \n",
    "    net_5.classify([data_t[1][x] for x in range(n-10, n)])\n",
    "    data_t[2].append(net_5.output[0])\n",
    "\n",
    "data_t[3] = data_t[1][0:12]\n",
    "for n in range(10, x_size-2):   \n",
    "    net_5.classify([data_t[1][x] for x in range(n-10, n)])\n",
    "    data_t[3].append(net_5.output[1])\n",
    "    \n",
    "data_t[4] = data_t[1][0:13]\n",
    "for n in range(10, x_size-3):   \n",
    "    net_5.classify([data_t[1][x] for x in range(n-10, n)])\n",
    "    data_t[4].append(net_5.output[2])\n",
    "\n",
    "plot_graph(data_t, \"Sequence\", \"x\", \"y\", labels = [\"real\", \"n+1\", \"n+2\", \"n+3\"], figsizex = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
