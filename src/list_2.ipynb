{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data import Instance, DataSet\n",
    "from miscellaneous import initialize_data, plot_graph, plot_points\n",
    "from neural_network import NeuralNetwork\n",
    "from activation_function import *\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descobrindo o número de instâncias e as dimensões de cada uma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances, dim_x, dim_y = x_train.shape\n",
    "num_instances += x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinamento\n",
    "norm_input_train = [np.divide(i.astype(np.float32),255).flatten() for i in x_train]\n",
    "\n",
    "output_train = []\n",
    "y = 10*[0.0]\n",
    "\n",
    "for n in y_train:\n",
    "    y[n] = 1.0\n",
    "    output_train.append(copy.deepcopy(y))\n",
    "    y[n] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teste\n",
    "norm_input_test = [np.divide(i.astype(np.float32),255).flatten() for i in x_test]\n",
    "\n",
    "output_test = []\n",
    "y = 10*[0.0]\n",
    "\n",
    "for n in y_test:\n",
    "    y[n] = 1.0\n",
    "    output_test.append(copy.deepcopy(y))\n",
    "    y[n] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizando o dataset para ser passado no padrão aceito pela rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet() \n",
    "\n",
    "for i,j in zip(norm_input_train + norm_input_test, output_train + output_test):\n",
    "    dataset.add(Instance(i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando as redes neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede neural 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = NeuralNetwork(dim_x*dim_y ,[10], [sig_func])\n",
    "data_1 = net_1.fit(dataset, \"batch\", 50, learning_rate = 0.1, type = \"class\", tvt_ratio = [len(norm_input_train), 0, len(norm_input_test)], \n",
    "                            print_info = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(data_1, \"Numbers\", \"Epoch\", \"Error\", figsizex = 16, figsizey = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede Neural 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede Neural 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
